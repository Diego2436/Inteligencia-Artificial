{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87bf98dd",
   "metadata": {},
   "source": [
    "### Repositorio\n",
    "https://github.com/Diego2436/Inteligencia-Artificial/\n",
    "### Nombres\n",
    "- Olmos Verdin Diego\n",
    "- Romero Hernández Oscar David\n",
    "- Valentin Ramos Emmanuel Guadalupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e79b0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29c79c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datasets\n",
    "datasets = {\n",
    "    \"Iris\": load_iris(),\n",
    "    \"Wine\": load_wine(),\n",
    "    \"Breast Cancer\": load_breast_cancer()\n",
    "}\n",
    "\n",
    "# Inicializar los clasificadores\n",
    "classifiers = {\n",
    "    \"Perceptrón Multicapa\":MLPClassifier(max_iter=1000, learning_rate_init=0.001, random_state=42),\n",
    "    \"Red Neuronal RBF\": MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', max_iter=1000, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f61bf",
   "metadata": {},
   "source": [
    "En este bloque de código, se cargan tres datasets predefinidos de la biblioteca **scikit-learn**: `Iris`, `Wine` y `Breast Cancer`, los cuales contienen datos etiquetados para problemas de clasificación. Estos datasets se almacenan en un diccionario llamado `datasets` para facilitar su manejo. Además, se inicializan dos clasificadores basados en redes neuronales: el **Perceptrón Multicapa**, configurado con un límite de 1000 iteraciones y una tasa de aprendizaje inicial de 0.001 para mejorar la convergencia, y una **Red Neuronal RBF**, configurada con una capa oculta de 100 neuronas y la función de activación `tanh` para emular una red basada en funciones de base radial. Estos clasificadores se almacenan en otro diccionario, `classifiers`, para su evaluación posterior en los diferentes conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a66fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar un clasificador\n",
    "def evaluate_classifier(name, classifier, X, y):\n",
    "    results = {\"Method\": [], \"Accuracy\": [], \"Confusion Matrix\": []}\n",
    "\n",
    "    # Hold-Out 70/30\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    results[\"Method\"].append(\"Hold-Out 70/30\")\n",
    "    results[\"Accuracy\"].append(accuracy)\n",
    "    results[\"Confusion Matrix\"].append(cm)\n",
    "\n",
    "    # 10-Fold Cross-Validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(classifier, X, y, cv=kf)\n",
    "    accuracy = cv_scores.mean()\n",
    "    classifier.fit(X, y)\n",
    "    y_pred = classifier.predict(X)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    results[\"Method\"].append(\"10-Fold Cross-Validation\")\n",
    "    results[\"Accuracy\"].append(accuracy)\n",
    "    results[\"Confusion Matrix\"].append(cm)\n",
    "\n",
    "    # Leave-One-Out Cross-Validation\n",
    "    loo = LeaveOneOut()\n",
    "    loo_scores = cross_val_score(classifier, X, y, cv=loo)\n",
    "    accuracy = loo_scores.mean()\n",
    "    classifier.fit(X, y)\n",
    "    y_pred = classifier.predict(X)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    results[\"Method\"].append(\"Leave-One-Out\")\n",
    "    results[\"Accuracy\"].append(accuracy)\n",
    "    results[\"Confusion Matrix\"].append(cm)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17a31ff",
   "metadata": {},
   "source": [
    "Esta función, llamada `evaluate_classifier`, tiene como objetivo entrenar y evaluar un clasificador utilizando tres métodos de validación diferentes: **Hold-Out 70/30**, **10-Fold Cross-Validation**, y **Leave-One-Out Cross-Validation**. \n",
    "\n",
    "1. **Hold-Out 70/30**: Divide los datos en un 70% para entrenamiento y un 30% para prueba. Luego, entrena el clasificador, realiza las predicciones sobre el conjunto de prueba y calcula la **precisión** (accuracy) y la **matriz de confusión** (confusion matrix). Estos resultados se almacenan en un diccionario bajo el método \"Hold-Out 70/30\".\n",
    "\n",
    "2. **10-Fold Cross-Validation**: Divide los datos en 10 subconjuntos, entrenando y evaluando el modelo 10 veces, cada vez utilizando un subconjunto diferente como conjunto de prueba y los otros 9 como entrenamiento. La **precisión promedio** se calcula a partir de las 10 iteraciones, y se genera una matriz de confusión sobre todos los datos.\n",
    "\n",
    "3. **Leave-One-Out Cross-Validation**: Similar a la validación cruzada de 10 pliegues, pero en este caso, el conjunto de entrenamiento consta de todos los ejemplos excepto uno, el cual se usa para prueba. Este proceso se repite para cada muestra, y la **precisión promedio** se calcula de todas las iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24becef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dataset: Iris ---\n",
      "\n",
      "Perceptrón Multicapa Results:\n",
      "                     Method  Accuracy                      Confusion Matrix\n",
      "0            Hold-Out 70/30  1.000000  [[19, 0, 0], [0, 13, 0], [0, 0, 13]]\n",
      "1  10-Fold Cross-Validation  0.973333  [[50, 0, 0], [0, 47, 3], [0, 0, 50]]\n",
      "2             Leave-One-Out  0.973333  [[50, 0, 0], [0, 47, 3], [0, 0, 50]] \n",
      "\n",
      "Red Neuronal RBF Results:\n",
      "                     Method  Accuracy                      Confusion Matrix\n",
      "0            Hold-Out 70/30  1.000000  [[19, 0, 0], [0, 13, 0], [0, 0, 13]]\n",
      "1  10-Fold Cross-Validation  0.973333  [[50, 0, 0], [0, 48, 2], [0, 1, 49]]\n",
      "2             Leave-One-Out  0.973333  [[50, 0, 0], [0, 48, 2], [0, 1, 49]] \n",
      "\n",
      "--- Dataset: Wine ---\n",
      "\n",
      "Perceptrón Multicapa Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Method  Accuracy                      Confusion Matrix\n",
      "0            Hold-Out 70/30  0.981481  [[18, 1, 0], [0, 21, 0], [0, 0, 14]]\n",
      "1  10-Fold Cross-Validation  0.943791  [[58, 1, 0], [0, 71, 0], [0, 0, 48]]\n",
      "2             Leave-One-Out  0.938202  [[58, 1, 0], [0, 71, 0], [0, 0, 48]] \n",
      "\n",
      "Red Neuronal RBF Results:\n",
      "                     Method  Accuracy                      Confusion Matrix\n",
      "0            Hold-Out 70/30  0.944444  [[18, 1, 0], [2, 19, 0], [0, 0, 14]]\n",
      "1  10-Fold Cross-Validation  0.943791  [[58, 1, 0], [0, 71, 0], [0, 0, 48]]\n",
      "2             Leave-One-Out  0.949438  [[58, 1, 0], [0, 71, 0], [0, 0, 48]] \n",
      "\n",
      "--- Dataset: Breast Cancer ---\n",
      "\n",
      "Perceptrón Multicapa Results:\n",
      "                     Method  Accuracy        Confusion Matrix\n",
      "0            Hold-Out 70/30  0.959064     [[57, 6], [1, 107]]\n",
      "1  10-Fold Cross-Validation  0.931391  [[193, 19], [14, 343]]\n",
      "2             Leave-One-Out  0.943761  [[193, 19], [14, 343]] \n",
      "\n",
      "Red Neuronal RBF Results:\n",
      "                     Method  Accuracy        Confusion Matrix\n",
      "0            Hold-Out 70/30  0.959064     [[62, 1], [6, 102]]\n",
      "1  10-Fold Cross-Validation  0.943703  [[199, 13], [17, 340]]\n",
      "2             Leave-One-Out  0.934974  [[199, 13], [17, 340]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar cada dataset y clasificador\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    X, y = dataset.data, dataset.target\n",
    "    print(f\"--- Dataset: {dataset_name} ---\\n\")\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        print(f\"{clf_name} Results:\")\n",
    "        clf_results = evaluate_classifier(clf_name, clf, X, y)\n",
    "        print(clf_results, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33c37c",
   "metadata": {},
   "source": [
    "Este bloque de código tiene como propósito evaluar el rendimiento de los clasificadores definidos previamente (Perceptrón Multicapa y Red Neuronal RBF) en cada uno de los datasets cargados (Iris, Wine y Breast Cancer). \n",
    "\n",
    "1. **Iteración sobre los datasets**: El código recorre cada dataset en el diccionario `datasets`. Para cada conjunto de datos (`X`, `y`), se extraen las características (`X`) y las etiquetas (`y`). Luego, se imprime el nombre del dataset actual para indicar cuál está siendo procesado.\n",
    "\n",
    "2. **Iteración sobre los clasificadores**: Luego, para cada clasificador en el diccionario `classifiers`, el código imprime el nombre del clasificador (`clf_name`) y evalúa su rendimiento utilizando la función `evaluate_classifier`. Esta función realiza el entrenamiento y la evaluación de cada clasificador mediante los tres métodos de validación definidos previamente (Hold-Out, Cross-Validation 10-Fold, y Leave-One-Out). Los resultados, que incluyen precisión y matrices de confusión, son impresos en la consola.\n",
    "\n",
    "3. **Impresión de los resultados**: Los resultados de la evaluación de cada clasificador en cada dataset se almacenan en un `DataFrame` y se imprimen para su revisión.\n",
    "\n",
    "Este bloque permite realizar una comparación directa de los clasificadores en los diferentes datasets y obtener un análisis detallado de su rendimiento bajo diversos métodos de validación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
