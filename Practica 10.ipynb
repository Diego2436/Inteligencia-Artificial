{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42efc377",
   "metadata": {},
   "source": [
    "### Repositorio\n",
    "https://github.com/Diego2436/Inteligencia-Artificial/\n",
    "### Nombres\n",
    "- Olmos Verdin Diego\n",
    "- Romero Hernández Oscar David\n",
    "- Valentin Ramos Emmanuel Guadalupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc9662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, LeaveOneOut\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cf4ea7",
   "metadata": {},
   "source": [
    "Se importa `numpy` para operaciones matemáticas y `pandas` para la manipulación de datos. `scikit-learn` se utiliza para cargar conjuntos de datos de ejemplo (`load_iris`, `load_wine`, `load_breast_cancer`), así como para realizar particiones de datos (`train_test_split`) y validación cruzada (`cross_val_score`, `KFold`, `LeaveOneOut`). Además, se importan clasificadores como `GaussianNB` (Naive Bayes) y `KNeighborsClassifier` (k-NN), junto con métricas de evaluación como `accuracy_score` y `confusion_matrix` para calcular la precisión y la matriz de confusión de las predicciones. El código proporciona las herramientas necesarias para aplicar diferentes algoritmos de clasificación y evaluar su desempeño en los conjuntos de datos de ejemplo utilizando validación cruzada y otros métodos de partición de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec13436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datasets\n",
    "datasets = {\n",
    "    \"Iris\": load_iris(),\n",
    "    \"Wine\": load_wine(),\n",
    "    \"Breast Cancer\": load_breast_cancer()\n",
    "}\n",
    "\n",
    "# Inicializar los clasificadores\n",
    "nb_classifier = GaussianNB()\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # Valor de K puede ajustarse según conveniencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78be2fe5",
   "metadata": {},
   "source": [
    "Se carga tres conjuntos de datos de ejemplo (`Iris`, `Wine`, y `Breast Cancer`) utilizando las funciones `load_iris()`, `load_wine()`, y `load_breast_cancer()` de la biblioteca `scikit-learn`, y los almacena en un diccionario llamado `datasets`, donde las claves son los nombres de los datasets y los valores son los datos cargados. Además, inicializa dos clasificadores: `nb_classifier`, que es un clasificador Naive Bayes (`GaussianNB()`), y `knn_classifier`, que es un clasificador k-Vecino más Cercano (`KNeighborsClassifier`), con `k=5` (el número de vecinos puede ajustarse según la necesidad del usuario). Estos clasificadores se utilizarán más adelante para realizar predicciones sobre los datos de los conjuntos mencionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b119cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar y evaluar un clasificador\n",
    "def evaluate_classifier(name, classifier, X, y):\n",
    "    results = {\"Method\": [], \"Accuracy\": [], \"Confusion Matrix\": []}\n",
    "\n",
    "    # Hold-Out 70/30\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    results[\"Method\"].append(\"Hold-Out 70/30\")\n",
    "    results[\"Accuracy\"].append(accuracy)\n",
    "    results[\"Confusion Matrix\"].append(cm)\n",
    "\n",
    "    # 10-Fold Cross-Validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(classifier, X, y, cv=kf)\n",
    "    accuracy = cv_scores.mean()\n",
    "    classifier.fit(X, y)\n",
    "    y_pred = classifier.predict(X)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    results[\"Method\"].append(\"10-Fold Cross-Validation\")\n",
    "    results[\"Accuracy\"].append(accuracy)\n",
    "    results[\"Confusion Matrix\"].append(cm)\n",
    "\n",
    "    # Leave-One-Out Cross-Validation\n",
    "    loo = LeaveOneOut()\n",
    "    loo_scores = cross_val_score(classifier, X, y, cv=loo)\n",
    "    accuracy = loo_scores.mean()\n",
    "    classifier.fit(X, y)\n",
    "    y_pred = classifier.predict(X)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    results[\"Method\"].append(\"Leave-One-Out\")\n",
    "    results[\"Accuracy\"].append(accuracy)\n",
    "    results[\"Confusion Matrix\"].append(cm)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3116d1",
   "metadata": {},
   "source": [
    "Este código define la función `evaluate_classifier`, que entrena y evalúa un clasificador utilizando tres métodos de validación: Hold-Out 70/30, validación cruzada 10-Fold y validación Leave-One-Out. La función toma como parámetros el nombre del clasificador (`name`), el clasificador en sí (`classifier`), y los datos (`X` para las características y `y` para las etiquetas). Primero, realiza una partición de los datos en entrenamiento y prueba utilizando Hold-Out 70/30, entrena el clasificador en los datos de entrenamiento, realiza predicciones sobre los datos de prueba, calcula la exactitud y la matriz de confusión, y almacena los resultados. Luego, realiza validación cruzada de 10 pliegues (`KFold`), calculando la exactitud promedio de las predicciones y la matriz de confusión sobre todo el conjunto de datos. Finalmente, aplica validación Leave-One-Out (`LeaveOneOut`), repitiendo el proceso para cada muestra del conjunto de datos, y guarda los resultados correspondientes. Los resultados de cada método se almacenan en un diccionario que se convierte en un DataFrame de `pandas`, que incluye el nombre del método, la exactitud obtenida y la matriz de confusión asociada para cada evaluación. Esta función es útil para comparar el rendimiento de un clasificador utilizando distintos métodos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "205e4d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dataset: Iris ---\n",
      "\n",
      "Naive Bayes Results:\n",
      "                     Method  Accuracy                      Confusion Matrix\n",
      "0            Hold-Out 70/30  0.977778  [[19, 0, 0], [0, 12, 1], [0, 0, 13]]\n",
      "1  10-Fold Cross-Validation  0.960000  [[50, 0, 0], [0, 47, 3], [0, 3, 47]]\n",
      "2             Leave-One-Out  0.953333  [[50, 0, 0], [0, 47, 3], [0, 3, 47]] \n",
      "\n",
      "KNN Results:\n",
      "                     Method  Accuracy                      Confusion Matrix\n",
      "0            Hold-Out 70/30  1.000000  [[19, 0, 0], [0, 13, 0], [0, 0, 13]]\n",
      "1  10-Fold Cross-Validation  0.973333  [[50, 0, 0], [0, 47, 3], [0, 2, 48]]\n",
      "2             Leave-One-Out  0.966667  [[50, 0, 0], [0, 47, 3], [0, 2, 48]] \n",
      "\n",
      "--- Dataset: Wine ---\n",
      "\n",
      "Naive Bayes Results:\n",
      "                     Method  Accuracy                      Confusion Matrix\n",
      "0            Hold-Out 70/30  1.000000  [[19, 0, 0], [0, 21, 0], [0, 0, 14]]\n",
      "1  10-Fold Cross-Validation  0.977778  [[58, 1, 0], [0, 70, 1], [0, 0, 48]]\n",
      "2             Leave-One-Out  0.977528  [[58, 1, 0], [0, 70, 1], [0, 0, 48]] \n",
      "\n",
      "KNN Results:\n",
      "                     Method  Accuracy                        Confusion Matrix\n",
      "0            Hold-Out 70/30  0.740741     [[17, 0, 2], [1, 15, 5], [1, 5, 8]]\n",
      "1  10-Fold Cross-Validation  0.664052  [[53, 1, 5], [6, 53, 12], [2, 12, 34]]\n",
      "2             Leave-One-Out  0.696629  [[53, 1, 5], [6, 53, 12], [2, 12, 34]] \n",
      "\n",
      "--- Dataset: Breast Cancer ---\n",
      "\n",
      "Naive Bayes Results:\n",
      "                     Method  Accuracy        Confusion Matrix\n",
      "0            Hold-Out 70/30  0.941520     [[57, 6], [4, 104]]\n",
      "1  10-Fold Cross-Validation  0.938409  [[189, 23], [10, 347]]\n",
      "2             Leave-One-Out  0.938489  [[189, 23], [10, 347]] \n",
      "\n",
      "KNN Results:\n",
      "                     Method  Accuracy       Confusion Matrix\n",
      "0            Hold-Out 70/30  0.959064    [[57, 6], [1, 107]]\n",
      "1  10-Fold Cross-Validation  0.936654  [[191, 21], [9, 348]]\n",
      "2             Leave-One-Out  0.933216  [[191, 21], [9, 348]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar cada dataset y clasificador\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    X, y = dataset.data, dataset.target\n",
    "    print(f\"--- Dataset: {dataset_name} ---\\n\")\n",
    "\n",
    "    # Naive Bayes\n",
    "    print(\"Naive Bayes Results:\")\n",
    "    nb_results = evaluate_classifier(\"Naive Bayes\", nb_classifier, X, y)\n",
    "    print(nb_results, \"\\n\")\n",
    "\n",
    "    # KNN\n",
    "    print(\"KNN Results:\")\n",
    "    knn_results = evaluate_classifier(\"KNN\", knn_classifier, X, y)\n",
    "    print(knn_results, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d940262d",
   "metadata": {},
   "source": [
    "Se recorre los conjuntos de datos cargados en el diccionario `datasets` y evalúa dos clasificadores (`Naive Bayes` y `KNN`) utilizando la función `evaluate_classifier`. Para cada conjunto de datos, se extraen las características (`X`) y las etiquetas (`y`), y se imprime el nombre del conjunto de datos. Luego, se realiza una evaluación para el clasificador Naive Bayes, pasando el clasificador `nb_classifier` y los datos a la función `evaluate_classifier`, cuyos resultados (precisión y matriz de confusión para cada método de validación) se imprimen en la consola. El mismo proceso se repite para el clasificador KNN, utilizando `knn_classifier`. Los resultados para ambos clasificadores se muestran por separado para cada conjunto de datos, permitiendo una comparación directa entre el rendimiento de ambos clasificadores en los diferentes métodos de validación (Hold-Out, 10-Fold Cross-Validation y Leave-One-Out)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
