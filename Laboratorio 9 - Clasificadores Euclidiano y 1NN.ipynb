{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e86cf1f",
   "metadata": {},
   "source": [
    "### Repositorio\n",
    "https://github.com/Diego2436/Inteligencia-Artificial/\n",
    "### Nombres\n",
    "- Olmos Verdin Diego\n",
    "- Romero Hernández Oscar David\n",
    "- Valentin Ramos Emmanuel Guadalupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e70e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4899104",
   "metadata": {},
   "source": [
    "Importa la biblioteca NumPy para realizar operaciones matemáticas y de álgebra lineal de manera eficiente.\n",
    "Importa el módulo datasets de la biblioteca scikit-learn, que es una biblioteca de machine learning en Python.\n",
    "\n",
    "load_iris: carga el conjunto de datos Iris, utilizado comúnmente en clasificación.\n",
    "load_wine: carga el conjunto de datos Wine, utilizado también en problemas de clasificación.\n",
    "load_breast_cancer: carga el conjunto de datos Breast Cancer, útil para problemas de clasificación binaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07c38d9",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2139ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Iris\": load_iris(),\n",
    "    \"Wine\": load_wine(),\n",
    "    \"Breast Cancer\": load_breast_cancer()\n",
    "}\n",
    "\n",
    "# Separar los datos y etiquetas de cada dataset\n",
    "dataset_data = {name: (data.data, data.target) for name, data in datasets.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21576dc9",
   "metadata": {},
   "source": [
    "Define un diccionario llamado datasets que almacena tres conjuntos de datos de ejemplo cargados con funciones de scikit-learn: load_iris, load_wine y load_breast_cancer. \n",
    "Las claves del diccionario son los nombres de los conjuntos de datos (\"Iris\", \"Wine\", y \"Breast Cancer\"), y los valores son los conjuntos de datos correspondientes.\n",
    "Crea un diccionario dataset_data que organiza y separa los datos y etiquetas (objetivo) de cada conjunto de datos. Usa una comprensión de diccionario para recorrer cada elemento en datasets. Para cada conjunto de datos:\n",
    "\n",
    "name representa el nombre del conjunto de datos.\n",
    "data.data contiene las características del conjunto de datos.\n",
    "data.target contiene las etiquetas de clasificación.\n",
    "Así, dataset_data almacenará una tupla (data, target) para cada conjunto de datos bajo su respectivo nombre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b06dd",
   "metadata": {},
   "source": [
    "## Paso 2: Implementación de clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f43ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_classifier(X_train, y_train, X_test):\n",
    "    # Calcular el centroide (media) de cada clase en el conjunto de entrenamiento\n",
    "    classes = np.unique(y_train)\n",
    "    centroids = {cls: X_train[y_train == cls].mean(axis=0) for cls in classes}\n",
    "    \n",
    "    # Asignar cada muestra de X_test a la clase con el centroide más cercano\n",
    "    y_pred = []\n",
    "    for x in X_test:\n",
    "        distances = {cls: np.linalg.norm(x - centroid) for cls, centroid in centroids.items()}\n",
    "        y_pred.append(min(distances, key=distances.get))\n",
    "    return np.array(y_pred)\n",
    "\n",
    "def knn_1_classifier(X_train, y_train, X_test):\n",
    "    y_pred = []\n",
    "    for x in X_test:\n",
    "        distances = np.linalg.norm(X_train - x, axis=1)\n",
    "        nearest_neighbor = np.argmin(distances)\n",
    "        y_pred.append(y_train[nearest_neighbor])\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb08512",
   "metadata": {},
   "source": [
    "La función `euclidean_classifier` clasifica muestras basándose en la distancia euclidiana entre cada muestra y el centroide (media) de cada clase en el conjunto de entrenamiento `X_train`. Primero, obtiene las clases únicas de `y_train` y calcula el centroide de cada clase usando una comprensión de diccionario. Luego, para cada muestra en `X_test`, calcula la distancia a cada centroide y asigna la clase correspondiente al centroide más cercano, devolviendo las predicciones como un array `y_pred`. Por otro lado, la función `knn_1_classifier` implementa un clasificador k-NN con `k=1`, donde cada muestra de prueba en `X_test` se clasifica según la clase de su vecino más cercano en `X_train`. Para cada muestra en `X_test`, calcula las distancias euclidianas a todas las muestras de `X_train`, identifica el índice de la muestra más cercana y asigna la clase correspondiente a esa muestra en `y_train`. Finalmente, devuelve un array `y_pred` con las clases predichas para cada muestra en `X_test`. Ambas funciones, basadas en distancias euclidianas, permiten clasificar puntos de prueba usando diferentes enfoques: el primero con centroides de clases y el segundo con vecinos individuales del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4175182e",
   "metadata": {},
   "source": [
    "## Paso 3: Implementación de métodos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d6da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificación en hold_out_validation para incluir el número de clases\n",
    "def hold_out_validation(X, y, classifier_func, test_size=0.3, random_seed=42):\n",
    "    # Número total de clases en el conjunto completo\n",
    "    num_classes = len(np.unique(y))\n",
    "    \n",
    "    # Dividir manualmente en entrenamiento y prueba\n",
    "    np.random.seed(random_seed)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    split_point = int(len(X) * (1 - test_size))\n",
    "    train_idx, test_idx = indices[:split_point], indices[split_point:]\n",
    "    \n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    y_pred = classifier_func(X_train, y_train, X_test)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    # Pasar num_classes a la función de matriz de confusión\n",
    "    conf_matrix = calculate_confusion_matrix(y_test, y_pred, num_classes)\n",
    "    return accuracy, conf_matrix\n",
    "\n",
    "# Modificación en cross_validation_kfold para incluir el número de clases\n",
    "def cross_validation_kfold(X, y, classifier_func, k=10):\n",
    "    n_samples = len(X)\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    fold_size = n_samples // k\n",
    "    num_classes = len(np.unique(y))  # Número total de clases en el conjunto completo\n",
    "    \n",
    "    accuracies = []\n",
    "    conf_matrix_sum = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    \n",
    "    for i in range(k):\n",
    "        test_idx = indices[i * fold_size:(i + 1) * fold_size]\n",
    "        train_idx = np.setdiff1d(indices, test_idx)\n",
    "        \n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        y_pred = classifier_func(X_train, y_train, X_test)\n",
    "        accuracies.append(np.mean(y_pred == y_test))\n",
    "        # Pasar num_classes a la función de matriz de confusión\n",
    "        conf_matrix_sum += calculate_confusion_matrix(y_test, y_pred, num_classes)\n",
    "    \n",
    "    accuracy = np.mean(accuracies)\n",
    "    return accuracy, conf_matrix_sum\n",
    "\n",
    "# Función de matriz de confusión que recibe el número total de clases\n",
    "def calculate_confusion_matrix(y_true, y_pred, num_classes):\n",
    "    # Crear matriz con el tamaño basado en el total de clases del dataset completo\n",
    "    matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        matrix[true_label, pred_label] += 1\n",
    "    return matrix\n",
    "\n",
    "# Modificación en leave_one_out_validation para incluir el número de clases\n",
    "def leave_one_out_validation(X, y, classifier_func):\n",
    "    n_samples = len(X)\n",
    "    accuracies = []\n",
    "    num_classes = len(np.unique(y))  # Número total de clases en el conjunto completo\n",
    "    conf_matrix_sum = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        X_train = np.concatenate((X[:i], X[i+1:]))\n",
    "        y_train = np.concatenate((y[:i], y[i+1:]))\n",
    "        X_test = X[i:i+1]\n",
    "        y_test = y[i:i+1]\n",
    "        \n",
    "        y_pred = classifier_func(X_train, y_train, X_test)\n",
    "        accuracies.append(y_pred[0] == y_test[0])\n",
    "        \n",
    "        # Pasar el número de clases a la función de matriz de confusión\n",
    "        conf_matrix_sum += calculate_confusion_matrix(y_test, y_pred, num_classes)\n",
    "    \n",
    "    accuracy = np.mean(accuracies)\n",
    "    return accuracy, conf_matrix_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479318ea",
   "metadata": {},
   "source": [
    "La función `hold_out_validation` divide el conjunto de datos en entrenamiento y prueba utilizando un porcentaje de división (`test_size`) y una semilla aleatoria (`random_seed`). Calcula el número total de clases en `y`, lo cual pasa a la función `calculate_confusion_matrix`, para construir la matriz de confusión de tamaño adecuado. Luego, entrena el clasificador (`classifier_func`) con el conjunto de entrenamiento, predice sobre el conjunto de prueba y calcula la exactitud (`accuracy`). La función `cross_validation_kfold` implementa validación cruzada k-fold dividiendo aleatoriamente `X` y `y` en `k` pliegues. Para cada pliegue, se usa como conjunto de prueba y los restantes como conjunto de entrenamiento; los resultados de las predicciones se acumulan en una matriz de confusión (`conf_matrix_sum`) y en una lista de exactitudes, promediando al final para obtener una exactitud general. La función `leave_one_out_validation` aplica validación cruzada de \"uno contra todos\" (`leave-one-out`), donde cada muestra individual se usa sucesivamente como conjunto de prueba y el resto como conjunto de entrenamiento. Cada predicción se evalúa en términos de exactitud y se acumula en `conf_matrix_sum`. Finalmente, la función `calculate_confusion_matrix` genera la matriz de confusión utilizando `y_true` y `y_pred` y el total de clases (`num_classes`), creando una matriz cuadrada que cuenta la frecuencia de cada combinación de etiquetas verdaderas y predichas. Estas funciones de validación han sido modificadas para considerar el número de clases en el conjunto de datos, garantizando que las matrices de confusión resultantes incluyan todas las clases posibles, aun cuando alguna clase no aparezca en un conjunto de prueba específico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cda78c",
   "metadata": {},
   "source": [
    "## Paso 4: Ejecutar la validación y calcular el desempeño "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7db93b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Iris\n",
      "\n",
      "Clasificador: Euclidean\n",
      "Hold Out (70/30) - Accuracy: 0.8889\n",
      "Matriz de Confusión:\n",
      " [[10  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  3 15]]\n",
      "10-Fold Cross-Validation - Accuracy: 0.9267\n",
      "Matriz de Confusión:\n",
      " [[50  0  0]\n",
      " [ 0 45  5]\n",
      " [ 0  6 44]]\n",
      "Leave-One-Out - Accuracy: 0.9200\n",
      "Matriz de Confusión:\n",
      " [[50  0  0]\n",
      " [ 0 45  5]\n",
      " [ 0  7 43]]\n",
      "\n",
      "Clasificador: 1-NN\n",
      "Hold Out (70/30) - Accuracy: 0.9778\n",
      "Matriz de Confusión:\n",
      " [[10  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  1 17]]\n",
      "10-Fold Cross-Validation - Accuracy: 0.9600\n",
      "Matriz de Confusión:\n",
      " [[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n",
      "Leave-One-Out - Accuracy: 0.9600\n",
      "Matriz de Confusión:\n",
      " [[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Dataset: Wine\n",
      "\n",
      "Clasificador: Euclidean\n",
      "Hold Out (70/30) - Accuracy: 0.7222\n",
      "Matriz de Confusión:\n",
      " [[12  0  3]\n",
      " [ 1 17  4]\n",
      " [ 1  6 10]]\n",
      "10-Fold Cross-Validation - Accuracy: 0.7235\n",
      "Matriz de Confusión:\n",
      " [[49  0  9]\n",
      " [ 3 46 18]\n",
      " [ 1 16 28]]\n",
      "Leave-One-Out - Accuracy: 0.7247\n",
      "Matriz de Confusión:\n",
      " [[50  0  9]\n",
      " [ 3 49 19]\n",
      " [ 1 17 30]]\n",
      "\n",
      "Clasificador: 1-NN\n",
      "Hold Out (70/30) - Accuracy: 0.6481\n",
      "Matriz de Confusión:\n",
      " [[13  1  1]\n",
      " [ 2 15  5]\n",
      " [ 1  9  7]]\n",
      "10-Fold Cross-Validation - Accuracy: 0.7647\n",
      "Matriz de Confusión:\n",
      " [[51  3  4]\n",
      " [ 5 50 12]\n",
      " [ 3 13 29]]\n",
      "Leave-One-Out - Accuracy: 0.7697\n",
      "Matriz de Confusión:\n",
      " [[52  3  4]\n",
      " [ 5 54 12]\n",
      " [ 3 14 31]]\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Dataset: Breast Cancer\n",
      "\n",
      "Clasificador: Euclidean\n",
      "Hold Out (70/30) - Accuracy: 0.8304\n",
      "Matriz de Confusión:\n",
      " [[44 28]\n",
      " [ 1 98]]\n",
      "10-Fold Cross-Validation - Accuracy: 0.8875\n",
      "Matriz de Confusión:\n",
      " [[151  58]\n",
      " [  5 346]]\n",
      "Leave-One-Out - Accuracy: 0.8910\n",
      "Matriz de Confusión:\n",
      " [[154  58]\n",
      " [  4 353]]\n",
      "\n",
      "Clasificador: 1-NN\n",
      "Hold Out (70/30) - Accuracy: 0.8947\n",
      "Matriz de Confusión:\n",
      " [[56 16]\n",
      " [ 2 97]]\n",
      "10-Fold Cross-Validation - Accuracy: 0.9143\n",
      "Matriz de Confusión:\n",
      " [[179  30]\n",
      " [ 18 333]]\n",
      "Leave-One-Out - Accuracy: 0.9156\n",
      "Matriz de Confusión:\n",
      " [[182  30]\n",
      " [ 18 339]]\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, (X, y) in dataset_data.items():\n",
    "    print(f\"Dataset: {dataset_name}\")\n",
    "    for classifier_name, classifier_func in [(\"Euclidean\", euclidean_classifier), (\"1-NN\", knn_1_classifier)]:\n",
    "        print(f\"\\nClasificador: {classifier_name}\")\n",
    "        \n",
    "        # Hold-Out\n",
    "        accuracy, conf_matrix = hold_out_validation(X, y, classifier_func)\n",
    "        print(f\"Hold Out (70/30) - Accuracy: {accuracy:.4f}\")\n",
    "        print(\"Matriz de Confusión:\\n\", conf_matrix)\n",
    "        \n",
    "        # 10-Fold Cross-Validation\n",
    "        accuracy, conf_matrix = cross_validation_kfold(X, y, classifier_func)\n",
    "        print(f\"10-Fold Cross-Validation - Accuracy: {accuracy:.4f}\")\n",
    "        print(\"Matriz de Confusión:\\n\", conf_matrix)\n",
    "        \n",
    "        # Leave-One-Out\n",
    "        accuracy, conf_matrix = leave_one_out_validation(X, y, classifier_func)\n",
    "        print(f\"Leave-One-Out - Accuracy: {accuracy:.4f}\")\n",
    "        print(\"Matriz de Confusión:\\n\", conf_matrix)\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b8029",
   "metadata": {},
   "source": [
    "Este código recorre cada conjunto de datos almacenado en `dataset_data`, imprimiendo primero el nombre del conjunto de datos. Para cada conjunto, aplica dos clasificadores: `euclidean_classifier` y `knn_1_classifier`. Dentro de cada clasificador, se evalúan tres métodos de validación: Hold-Out, 10-Fold Cross-Validation y Leave-One-Out. En la validación Hold-Out, la función `hold_out_validation` divide los datos en un 70% para entrenamiento y 30% para prueba, calculando la exactitud (`accuracy`) y la matriz de confusión (`conf_matrix`). En la validación 10-Fold Cross-Validation, `cross_validation_kfold` divide los datos en 10 pliegues, donde cada pliegue se usa sucesivamente como conjunto de prueba, acumulando la exactitud media y una matriz de confusión global. En Leave-One-Out, `leave_one_out_validation` evalúa cada muestra como conjunto de prueba individual mientras el resto sirve de entrenamiento, generando una exactitud media y una matriz de confusión sumada. Para cada método de validación, imprime la exactitud con cuatro decimales y la matriz de confusión resultante. Al final de cada clasificador, se imprime una línea divisoria para separar los resultados de cada conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031ae94c",
   "metadata": {},
   "source": [
    "## Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "882a61a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Iris\n",
      "\n",
      "Clasificador: Euclidean\n",
      "Hold Out (70/30) - Accuracy: 0.9556\n",
      "Matriz de Confusión:\n",
      " [[19  0  0]\n",
      " [ 0 11  2]\n",
      " [ 0  0 13]]\n",
      "10-Fold Cross-Validation - Accuracy: 0.9267\n",
      "Matriz de Confusión:\n",
      " [[50  0  0]\n",
      " [ 0 45  5]\n",
      " [ 0  6 44]]\n",
      "Leave-One-Out - Accuracy: 0.9200\n",
      "Matriz de Confusión:\n",
      " [[50  0  0]\n",
      " [ 0 45  5]\n",
      " [ 0  7 43]]\n",
      "\n",
      "Clasificador: 1-NN\n",
      "Hold Out (70/30) - Accuracy: 1.0000\n",
      "Matriz de Confusión:\n",
      " [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "10-Fold Cross-Validation - Accuracy: 0.9600\n",
      "Matriz de Confusión:\n",
      " [[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n",
      "Leave-One-Out - Accuracy: 0.9600\n",
      "Matriz de Confusión:\n",
      " [[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Dataset: Wine\n",
      "\n",
      "Clasificador: Euclidean\n",
      "Hold Out (70/30) - Accuracy: 0.7593\n",
      "Matriz de Confusión:\n",
      " [[17  0  2]\n",
      " [ 0 14  7]\n",
      " [ 0  4 10]]\n",
      "10-Fold Cross-Validation - Accuracy: 0.7248\n",
      "Matriz de Confusión:\n",
      " [[50  0  9]\n",
      " [ 3 49 19]\n",
      " [ 1 17 30]]\n",
      "Leave-One-Out - Accuracy: 0.7247\n",
      "Matriz de Confusión:\n",
      " [[50  0  9]\n",
      " [ 3 49 19]\n",
      " [ 1 17 30]]\n",
      "\n",
      "Clasificador: 1-NN\n",
      "Hold Out (70/30) - Accuracy: 0.7963\n",
      "Matriz de Confusión:\n",
      " [[17  0  2]\n",
      " [ 3 16  2]\n",
      " [ 1  3 10]]\n",
      "10-Fold Cross-Validation - Accuracy: 0.7310\n",
      "Matriz de Confusión:\n",
      " [[52  3  4]\n",
      " [ 5 52 14]\n",
      " [ 3 19 26]]\n",
      "Leave-One-Out - Accuracy: 0.7697\n",
      "Matriz de Confusión:\n",
      " [[52  3  4]\n",
      " [ 5 54 12]\n",
      " [ 3 14 31]]\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Dataset: Breast Cancer\n",
      "\n",
      "Clasificador: Euclidean\n",
      "Hold Out (70/30) - Accuracy: 0.9181\n",
      "Matriz de Confusión:\n",
      " [[ 49  14]\n",
      " [  0 108]]\n",
      "10-Fold Cross-Validation - Accuracy: 0.8910\n",
      "Matriz de Confusión:\n",
      " [[153  59]\n",
      " [  3 354]]\n",
      "Leave-One-Out - Accuracy: 0.8910\n",
      "Matriz de Confusión:\n",
      " [[154  58]\n",
      " [  4 353]]\n",
      "\n",
      "Clasificador: 1-NN\n",
      "Hold Out (70/30) - Accuracy: 0.9357\n",
      "Matriz de Confusión:\n",
      " [[ 56   7]\n",
      " [  4 104]]\n",
      "10-Fold Cross-Validation - Accuracy: 0.9191\n",
      "Matriz de Confusión:\n",
      " [[182  30]\n",
      " [ 16 341]]\n",
      "Leave-One-Out - Accuracy: 0.9156\n",
      "Matriz de Confusión:\n",
      " [[182  30]\n",
      " [ 18 339]]\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "# Cargar datasets\n",
    "datasets = {\n",
    "    \"Iris\": load_iris(),\n",
    "    \"Wine\": load_wine(),\n",
    "    \"Breast Cancer\": load_breast_cancer()\n",
    "}\n",
    "\n",
    "# Diccionario para almacenar los clasificadores\n",
    "classifiers = {\n",
    "    \"Euclidean\": NearestCentroid(),\n",
    "    \"1-NN\": KNeighborsClassifier(n_neighbors=1)\n",
    "}\n",
    "\n",
    "# Función para realizar validación hold-out\n",
    "def hold_out_validation(X, y, classifier):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    return accuracy, conf_matrix\n",
    "\n",
    "# Función para realizar validación cruzada k-fold\n",
    "def cross_validation_kfold(X, y, classifier, k=10):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    accuracies = cross_val_score(classifier, X, y, cv=kf)\n",
    "    classifier.fit(X, y)\n",
    "    y_pred = cross_val_score(classifier, X, y, cv=kf, scoring=\"accuracy\")\n",
    "    # Generamos la matriz de confusión sumando todas las matrices de los pliegues\n",
    "    conf_matrix_sum = np.zeros((len(np.unique(y)), len(np.unique(y))), dtype=int)\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        classifier.fit(X[train_idx], y[train_idx])\n",
    "        y_pred = classifier.predict(X[test_idx])\n",
    "        conf_matrix_sum += confusion_matrix(y[test_idx], y_pred)\n",
    "    return np.mean(accuracies), conf_matrix_sum\n",
    "\n",
    "# Función para realizar leave-one-out cross validation\n",
    "def leave_one_out_validation(X, y, classifier):\n",
    "    loo = LeaveOneOut()\n",
    "    y_true, y_pred = [], []\n",
    "    for train_idx, test_idx in loo.split(X):\n",
    "        classifier.fit(X[train_idx], y[train_idx])\n",
    "        pred = classifier.predict(X[test_idx])\n",
    "        y_true.extend(y[test_idx])\n",
    "        y_pred.extend(pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    return accuracy, conf_matrix\n",
    "\n",
    "# Aplicamos las validaciones a cada dataset y clasificador\n",
    "for dataset_name, data in datasets.items():\n",
    "    X, y = data.data, data.target\n",
    "    print(f\"Dataset: {dataset_name}\")\n",
    "    for classifier_name, classifier in classifiers.items():\n",
    "        print(f\"\\nClasificador: {classifier_name}\")\n",
    "        \n",
    "        # Hold-Out\n",
    "        accuracy, conf_matrix = hold_out_validation(X, y, classifier)\n",
    "        print(f\"Hold Out (70/30) - Accuracy: {accuracy:.4f}\")\n",
    "        print(\"Matriz de Confusión:\\n\", conf_matrix)\n",
    "        \n",
    "        # 10-Fold Cross-Validation\n",
    "        accuracy, conf_matrix = cross_validation_kfold(X, y, classifier)\n",
    "        print(f\"10-Fold Cross-Validation - Accuracy: {accuracy:.4f}\")\n",
    "        print(\"Matriz de Confusión:\\n\", conf_matrix)\n",
    "        \n",
    "        # Leave-One-Out\n",
    "        accuracy, conf_matrix = leave_one_out_validation(X, y, classifier)\n",
    "        print(f\"Leave-One-Out - Accuracy: {accuracy:.4f}\")\n",
    "        print(\"Matriz de Confusión:\\n\", conf_matrix)\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d35f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
